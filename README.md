# ppae

## Successful experiments:
- RNN encoder: hidden size 64, latent size 10, lam_TV = 1, lam_latent = 0.01

## Current problem

## TODO list
- Think about MLP structure. Might need convolutional and recurrent layers
- Some tricks heard from Pavlos' talk on Oct 18 that might worth integrating:
    - Include smoothness contraint of the rate function into the loss (derivative available from back propagation)
